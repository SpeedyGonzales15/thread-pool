# Отчет по реализации кастомного пула потоков

---

## Анализ производительности

Реализованный кастомный пул потоков предоставляет гибкие возможности управления количеством потоков, очередями и политикой отказов, что позволяет адаптировать его под специфичные сценарии высоконагруженных серверных приложений. В сравнении со стандартным `ThreadPoolExecutor` из Java:

- **Преимущества кастомного пула:**
  - Возможность точной настройки минимального числа резервных потоков (`minSpareThreads`), что снижает задержки при всплесках нагрузки.
  - Распределение задач по нескольким очередям с привязкой к рабочим потокам, что позволяет избежать узких мест в одной общей очереди.
  - Гибкая политика отказов с явным логированием и возможностью расширения.

- **Недостатки по сравнению со стандартными пулами:**
  - Более высокая сложность реализации и потенциальные накладные расходы на синхронизацию.
  - Отсутствие глубоких оптимизаций и тонкой настройки, реализованных в зрелых решениях (например, Tomcat, Jetty).
  - Меньшая устойчивость к крашам и исключениям без дополнительной доработки.

В целом, для большинства типовых задач стандартные пулы эффективнее и надежнее, но кастомный пул полезен, когда необходима специфичная логика управления потоками и очередями.

---

## Мини-исследование параметров пула

- **corePoolSize и maxPoolSize:**  
  Оптимальные значения зависят от числа доступных CPU и характера задач. Для CPU-интенсивных задач рекомендуется corePoolSize близкое к числу ядер, maxPoolSize — немного больше для обработки пиков. Для IO-интенсивных задач можно увеличить maxPoolSize.

- **queueSize:**  
  Слишком маленькая очередь приводит к частым отказам, слишком большая — к задержкам и росту времени ожидания. В тестах оптимально показал себя размер очереди около 5-10 задач.

- **keepAliveTime:**  
  Значение в несколько секунд (например, 5 секунд) позволяет эффективно освобождать неиспользуемые потоки без частого создания/завершения.

- **minSpareThreads:**  
  Поддержание 1-2 резервных потоков снижает задержки при появлении новых задач, но увеличивает потребление ресурсов.

---

## Принцип работы распределения задач

В реализации используется **Round Robin** распределение задач по нескольким очередям, каждая из которых привязана к своему рабочему потоку. При поступлении задачи пул последовательно пытается добавить ее в очереди по кругу. Если все очереди заполнены и пул еще не достиг максимального размера, создается новый поток с новой очередью. Если максимальное число потоков достигнуто и очереди переполнены — задача отклоняется.

Такой подход обеспечивает равномерное распределение нагрузки и предотвращает перегрузку отдельных потоков, при этом не требует сложных вычислений и синхронизаций.
